{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TILT - Teemo Induced Loss of Tranquility\n",
    "A research project to study main factors in inducing tilt.\n",
    "\n",
    "ONLY LOOKS AT THE PERSON STATS THEMSELVES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from pathlib2 import Path\n",
    "from riotwatcher import LolWatcher, ApiError\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "\n",
    "# import arrow\n",
    "# import csv\n",
    "import itertools\n",
    "# import datetime\n",
    "# import time\n",
    "import json\n",
    "# import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_patch_time(reg, patch_nr=\"now\"):\n",
    "    \"\"\"\n",
    "    Read the patch number and return the time adjusted for time shift caused by different timezones.  \n",
    "    Args:\n",
    "        reg (str): Official registered Riot server that hosts league of legends.\n",
    "        patch_nr (str): League of legends update patch number. \n",
    "            Defaults to \"now\" which is the current time.\n",
    "    Returns:\n",
    "        adj_time (long): Time in (milli)seconds following the Coordinated Universal Time (UTC) format.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Read patch data\n",
    "    patch_loc = proj_dir / \"data\" / \"patches.json\"\n",
    "    with open(patch_loc, \"r\") as in_file:\n",
    "        patch_data = json.load(in_file)\n",
    "    \n",
    "    # Set the base utc time\n",
    "    patch_time = None\n",
    "    if patch_nr == \"now\":\n",
    "        patch_time = int(str(datetime.utcnow().timestamp())[:10])\n",
    "    else:\n",
    "        for patch in patch_data[\"patches\"]:\n",
    "            if patch[\"name\"] == patch_nr:\n",
    "                patch_time = patch[\"start\"]\n",
    "        # Return error if a wrong patch nr is provided\n",
    "        if not patch_time:\n",
    "            print(f\"Patch number: {patch_nr} was not found\")\n",
    "            sys.exit(0)\n",
    "\n",
    "    # Set the time shift\n",
    "    try:\n",
    "        reg_shifts = patch_data[\"shifts\"][reg.upper()]\n",
    "    except KeyError:\n",
    "        # Return error if a wrong region is provided\n",
    "        print(f\"Region: {reg} is unknown\")\n",
    "        sys.exit(0) \n",
    "    \n",
    "    # Calculate time adjusted for the time shift of the region\n",
    "    adj_time = patch_time+reg_shifts\n",
    "    return adj_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def api_key(api_key_loc):\n",
    "    \"\"\"\n",
    "    Read in the development API key from a file and checks if it is viable.\n",
    "    \n",
    "    Args:\n",
    "        credentials (str): Name of json file containing the credentials.\n",
    "    Returns:\n",
    "        api_key (str): The API key.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        with open(api_key_loc, \"r\") as credentials:\n",
    "            creds = json.load(credentials)\n",
    "            api_key = creds[\"dev_api_key\"]\n",
    "            lol_watcher = LolWatcher(creds[\"dev_api_key\"])\n",
    "            try:\n",
    "                # Validate API key by using it to check server status\n",
    "                lol_watcher.lol_status.shard_data(\"euw1\")\n",
    "                # Break if key is functional\n",
    "                break\n",
    "            except ApiError as error:\n",
    "                # If the current API key does not work input new one\n",
    "                if error.response.status_code == 403:\n",
    "                    new_api_key = input(\"API key is incorrect, enter correct key here.\")\n",
    "                    creds[\"dev_api_key\"] = new_api_key\n",
    "                    # Replace the old API key\n",
    "                    with open(api_key_loc, \"w\") as json_data:\n",
    "                        json.dump(creds, json_data)\n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_reg(reg_abbrv):\n",
    "    \"\"\"\n",
    "    Translate a league of legends region into a region readable by riot watcher.\n",
    "    \n",
    "    Args:\n",
    "        reg_abbrv (str): Abbreviation of a official registered Riot servers that\n",
    "            hosts league of legends (e.g. euw1).\n",
    "    Returns:\n",
    "        rw_region (str): Riot Watcher region the reg_abbrv server falls under.\n",
    "    \"\"\"\n",
    "    # Look up in the list what the riot watcher region is for the given region abbreviation\n",
    "    regions_metadata = {\"br1\": \"americas\",\n",
    "                        \"eun1\": \"europe\",\n",
    "                        \"euw1\": \"europe\",\n",
    "                        \"jp1\": \"asia\",\n",
    "                        \"kr\": \"asia\",\n",
    "                        \"la1\": \"americas\",\n",
    "                        \"la2\": \"americas\",\n",
    "                        \"na1\": \"americas\",\n",
    "                        \"oc1\": \"americas\",\n",
    "                        \"tr1\": \"europe\",\n",
    "                        \"ru\": \"europe\"\n",
    "                        }\n",
    "\n",
    "    for reg, rw_reg in regions_metadata.items():\n",
    "        if reg_abbrv.lower() == reg:\n",
    "            rw_region = rw_reg\n",
    "    \n",
    "    return rw_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=1, min=5, max=60), stop=stop_after_attempt(10))\n",
    "def get_matches(reg, pid, s_time, e_time):\n",
    "    \"\"\"\n",
    "    Retrieve match IDs from a summoner within a given timeframe.\n",
    "\n",
    "    Args:\n",
    "        reg (str): Abbreviation of a official registered Riot servers that\n",
    "            hosts league of legends (e.g. euw1).\n",
    "        pid (str): An Encrypted globally unique identifyer for a summoner.\n",
    "        s_time (long): Start of a timeframe in (milli)seconds following\n",
    "            the Coordinated Universal Time (UTC) format.\n",
    "        e_time (long): end of a timeframe in (milli)seconds following\n",
    "            the Coordinated Universal Time (UTC) format.\n",
    "    Returns:\n",
    "        matches (list): League of legends match IDs in chronological order\n",
    "            starting with the most recent match.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve all match ID's between two time points\n",
    "    rw_reg = trans_reg(reg)\n",
    "    matches = lol_watcher.match.matchlist_by_puuid(region=rw_reg,\n",
    "                                                   puuid=pid,\n",
    "                                                   start_time=s_time,\n",
    "                                                   count=100,\n",
    "                                                   queue=420,\n",
    "                                                   end_time=e_time)\n",
    "    \n",
    "    # Geather more match IDs in case matches exceeds the standard limit of 100\n",
    "    while len(matches) % 100 == 0 and len(matches) != 0:\n",
    "        # Geather match details of earliest match\n",
    "        match_deets = lol_watcher.match.by_id(rw_reg, matches[-1])\n",
    "        # Start time of earliest match\n",
    "        early_g_start = int(str(match_deets[\"info\"]['gameCreation'])[:10])\n",
    "        # Select 100 matches previous to early_g_start  \n",
    "        match_add = lol_watcher.match.matchlist_by_puuid(region=rw_reg,\n",
    "                                                         puuid=pid,\n",
    "                                                         start_time=s_time,\n",
    "                                                         count=100,\n",
    "                                                         queue=420,\n",
    "                                                         end_time=early_g_start)\n",
    "        if len(match_add) == 0:\n",
    "            break\n",
    "        else:\n",
    "            matches.extend(match_add)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=1, min=5, max=60), stop=stop_after_attempt(10))\n",
    "def geather_data(puuid, matches):\n",
    "    \"\"\"\n",
    "    Geather summoner data from a match and chronology data of the match.\n",
    "    \n",
    "    Args:\n",
    "        puuid (str): An Encrypted globally unique identifyer for a summoner.\n",
    "        matches (list): League of legends match IDs in chronological order\n",
    "                        starting with the most recent matches.  \n",
    "    Returns:\n",
    "        df_matches_data (df): Data geathered from matches of a summoner.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_info = [\"gameCreation\", \"gameStartTimestamp\", \"gameDuration\"]\n",
    "    keep_data = [\"puuid\", \"teamPosition\", \"kills\", \"assists\", \"deaths\", \n",
    "                 \"doubleKills\", \"tripleKills\", \"quadraKills\", \"pentaKills\", \n",
    "                 \"killingSprees\", \"largestKillingSpree\", \n",
    "                 \"teamEarlySurrendered\", \"gameEndedInEarlySurrender\", \"gameEndedInSurrender\",\n",
    "                 \"neutralMinionsKilled\", \"totalMinionsKilled\", \"teamId\", \"win\"]\n",
    "\n",
    "    col_names = [\"match_id\", \"puuid\", \"pos\", \"kills\", \"assists\", \"deaths\", \n",
    "                 \"2_kills\", \"3_kills\", \"4_kills\", \"5_kills\", \n",
    "                 \"kill_spree\", \"max_kill_spree\", \n",
    "                 \"early_surr\", \"remake\", \"game_surr\",\n",
    "                 \"neutral_kills\", \"mini_kills\", \"team_id\", \"win\",\n",
    "                 \"game_make\", \"game_start\", \"game_dur\"]\n",
    "      \n",
    "    comp_data = []\n",
    "    # Geather match details\n",
    "    for match_id in matches:\n",
    "        reg = match_id.split(\"_\")[0].lower()\n",
    "        match_deets = lol_watcher.match.by_id(trans_reg(reg), match_id)\n",
    "\n",
    "        # Skip if the match was not a ranked solo 5 Versus 5 game\n",
    "        #       \n",
    "        # Collect time data\n",
    "        time_data = dict((key, match_deets[\"info\"][key]) for key in time_info)\n",
    "\n",
    "        # Collect summoner data       \n",
    "        for part_info in match_deets[\"info\"][\"participants\"]:\n",
    "            if part_info[\"puuid\"] == puuid:\n",
    "                filt_data = dict((key, part_info[key]) for key in keep_data)\n",
    "        match_data = {\"match_id\": match_id} | filt_data | time_data\n",
    "        comp_data.append(match_data.values())\n",
    "    \n",
    "    # Store all data in a dataframe\n",
    "    df_matches_data = pd.DataFrame(comp_data, columns=col_names)\n",
    "\n",
    "    return df_matches_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_matches(matches_data, max_rest, min_streak):\n",
    "    \"\"\"\n",
    "    Filter matches based on rest time in between matches and number of matches played in a row.  \n",
    "    \n",
    "    Args:\n",
    "        matches_data (df): Data geathered from matches of a summoner.\n",
    "        max_rest (int): Rest time in between matches in miliseconds e.g. 3600000 = 1 hour.\n",
    "        min_streak (int): Minimum games played in a row with less then max_rest between.\n",
    "    Returns:\n",
    "        df_match_filt (df): Matches filtered based on minuum subsequent matches within\n",
    "            the maximum rest time in between the matches.\n",
    "    \"\"\"\n",
    "      \n",
    "    # Filter for matches based on rest time\n",
    "\n",
    "    # Add rest time\n",
    "    df_match_filt = matches_data \n",
    "    df_match_filt[\"game_end\"] = df_match_filt.loc[:,[\"game_start\", \"game_dur\"]].sum(axis=1)\n",
    "    df_match_filt[\"prev_game_make\"] = df_match_filt[\"game_make\"].shift(-1, fill_value=0)\n",
    "    df_match_filt[\"rest_time\"] = df_match_filt[\"game_end\"] - df_match_filt[\"prev_game_make\"]\n",
    "\n",
    "\n",
    "    # Store if the game ID should be kept if rest time is below max_rest\n",
    "    df_match_filt['keep'] = df_match_filt[\"rest_time\"] <= max_rest\n",
    "    # Grouping based on matches played subsequently \n",
    "    subseq_true = df_match_filt['keep'].diff().ne(0).cumsum()\n",
    "    # Drop streaks that are lower then min_streak\n",
    "    df_match_filt = df_match_filt[df_match_filt['keep'].groupby(subseq_true).transform(\"count\") >= min_streak]\n",
    "    # Drop matches with rest times above max_rest \n",
    "    df_match_filt = df_match_filt[~(df_match_filt[\"keep\"] == 0.0)]\n",
    "\n",
    "    # Add the streak id to the df_match_filt\n",
    "    df_match_filt[\"streak_id\"] = df_match_filt.groupby(subseq_true).grouper.group_info[0]\n",
    "\n",
    "    # Remove the keep column \n",
    "    df_match_filt.drop(\"keep\", axis=1, inplace = True)\n",
    "    \n",
    "    return df_match_filt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summoner_data(regs, tiers, divs, sum_lim, p_patch, r_patch, max_rest, min_streak, sumo_data_out):\n",
    "    \"\"\"\n",
    "    Get puuid's, tier and division, from all regions that are in ranks below master rank ((random?) above bronze?).\n",
    "    \n",
    "    Args:\n",
    "        regs (list): Official registered Riot servers that hosts league of legends.\n",
    "        tier (list): Tiers below Master rank.\n",
    "        divs (list): Divisions in roman numerals.\n",
    "        sum_lim (int): Maximum number of summoner ids to collect per region, tier and division.\n",
    "        p_patch (str): A patch prior to then r_patch's patch.\n",
    "        r_patch (str): A more recent patch then p_patch's patch.\n",
    "        max_rest (int): Rest time in between matches in miliseconds e.g. 3600000 = 1 hour.\n",
    "        min_streak (int): Minimum games played in a row with less then max_rest between.\n",
    "        sumo_data_out (str): location to store the info on the summoner and game statistics.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    for reg, tier, div in itertools.product(regs, tiers, divs):\n",
    "        summs_div = 0\n",
    "        page_nr = 0\n",
    "        # Keep adding new summoners until the summoner limit has been reached\n",
    "        while summs_div < sum_lim:\n",
    "            page_nr += 1\n",
    "            summs = lol_watcher.league.entries(reg, \"RANKED_SOLO_5x5\", tier, div, page_nr)\n",
    "            # Look into data per summoner\n",
    "            for sumo in summs:\n",
    "                if summs_div < sum_lim:\n",
    "                    # Get PUUID\n",
    "                    pid = lol_watcher.summoner.by_id(reg, sumo[\"summonerId\"])[\"puuid\"]\n",
    "\n",
    "                    # Retrieve all match ID's between two time points\n",
    "                    match_ids = get_matches(reg, pid, adj_patch_time(reg, p_patch), adj_patch_time(reg, r_patch))\n",
    "                    # Skip summoners that have no matches in the given time frame \n",
    "                    if not match_ids:\n",
    "                        continue\n",
    "        \n",
    "                    # Geather match data of the summoner\n",
    "                    match_info = geather_data(pid, match_ids)\n",
    "\n",
    "                    # Filter matches\n",
    "                    filt_match_info = filt_matches(match_info, max_rest, min_streak)\n",
    "                    # Skip summoners that have no matches left after filtering\n",
    "                    if filt_match_info.empty:\n",
    "                        continue\n",
    "                    \n",
    "                    # Add summoner rank information \n",
    "                    cur_rank = f\"{tier}_{div}\"\n",
    "                    filt_match_info.insert (2, \"rank\", cur_rank)\n",
    "\n",
    "                    # Increase the summoner counter\n",
    "                    summs_div += 1\n",
    "                    \n",
    "                    # Store summoner data in a tsv file\n",
    "                    file_true = sumo_data_out.exists()\n",
    "                    filt_match_info.to_csv(sumo_data_out,\n",
    "                                           header=not file_true,\n",
    "                                           mode='a' if file_true else 'w',\n",
    "                                           sep=\"\\t\",\n",
    "                                           index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory locations\n",
    "\n",
    "# Project folders\n",
    "proj_dir = Path.cwd().parent\n",
    "\n",
    "# Raw data storage\n",
    "data_dir = proj_dir / \"data\"\n",
    "\n",
    "# Out dir\n",
    "out_dir = proj_dir / \"out\"\n",
    "\n",
    "# Gobal variables\n",
    "\n",
    "# Set API key\n",
    "api_key_loc = data_dir / \"dev_api_key.json\"\n",
    "\n",
    "# Enter API key\n",
    "lol_watcher = LolWatcher(api_key(api_key_loc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the summoner info of n summoners\n",
    "\n",
    "# Remove output file if it exists\n",
    "out_file_path = out_dir / \"summoner_data.tsv\"\n",
    "if out_file_path.exists():\n",
    "    answer = input(\"A file with the same name is present are you sure you want to overwrite it? Enter yes or no\")\n",
    "    if answer.upper() in [\"Y\", \"YES\"]:\n",
    "        os.remove(out_file_path)\n",
    "    else:\n",
    "        sys.exit(0)\n",
    "\n",
    "# Read user settings\n",
    "settings_loc = proj_dir / \"settings\" / \"config.json\"\n",
    "with open(settings_loc, \"r\") as settings_data:\n",
    "    settings = json.load(settings_data)\n",
    "\n",
    "get_summoner_data(regs=settings[\"regions\"],\n",
    "                  tiers=settings[\"tiers\"],\n",
    "                  divs=settings['divisions'],\n",
    "                  sum_lim=settings['summoner_limit'],\n",
    "                  p_patch=settings[\"prior_patch\"],\n",
    "                  r_patch=settings[\"recent_patch\"],\n",
    "                  max_rest=settings[\"max_rest\"],\n",
    "                  min_streak=settings[\"min_streak\"],\n",
    "                  sumo_data_out=out_dir / \"summoner_data.tsv\")\n",
    "\n",
    "\n",
    "\n",
    "# # Read in the summoner data\n",
    "# sumo_info = pd.read_csv(summs_data_out, sep = \"\\t\")\n",
    "\n",
    "\n",
    "# print(summs_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base line\n",
    "# base line = all games of a player\n",
    "# tilt is calculated as win % er streak increase or decrease\n",
    "# % win on first game\n",
    "# % win on secoond game\n",
    "# % win on third game etc\n",
    "\n",
    "# make 2 datasets games long rest, games short rest \n",
    "# long rest >\n",
    "# short rest <=\n",
    "# \n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance of rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REst time vs win rate plot\n",
    "# \n",
    "# check if player has games with short rest take all games fitler is done later in data analysis\n",
    "# \n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHen to players play? \n",
    "# player to time point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tilt or in the zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winrate increase or decrease by factor of previous game\n",
    "# base winrate?\n",
    "# define good and bad stats using medians/average normal dist? \n",
    "# Win rate in next game after losing with bad stats\n",
    "# Win rate in next game after losing with good stats\n",
    "# Win rate in next game after winning with bad stats\n",
    "# Win rate in next game after winning with good stats\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86fe447469a8d852eea4b65c790d87be74d102a869903b8cc8b4ce651f2c3448"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tilt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
