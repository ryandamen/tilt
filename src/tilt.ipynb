{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TILT - Teemo Induced Loss of Tranquility\n",
    "A research project to study main factors in inducing tilt.\n",
    "\n",
    "ONLY LOOKS AT THE PERSON STATS THEMSELVES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from pathlib2 import Path\n",
    "from riotwatcher import LolWatcher, ApiError\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "\n",
    "# import arrow\n",
    "# import csv\n",
    "import itertools\n",
    "# import datetime\n",
    "# import time\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def touch(path):\n",
    "    \"\"\"\n",
    "    Creates a file if it doesnt exists and also create any directories in the path that do not exist.\n",
    "\n",
    "    Args:\n",
    "        path (str): File path.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    basedir = os.path.dirname(path)\n",
    "    if not os.path.exists(basedir):\n",
    "        os.makedirs(basedir)\n",
    "    with open(path, mode='a'):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_key(api_key_loc):\n",
    "    \"\"\"\n",
    "    Read in the development API key from a file and checks if it is viable.\n",
    "    \n",
    "    Args:\n",
    "        credentials (str): Name of json file containing the credentials.\n",
    "    Returns:\n",
    "        api_key (str): The API key.\n",
    "    \"\"\"\n",
    "\n",
    "    # Keep requestion for a correct key or until canceled\n",
    "    while True:\n",
    "        with open(api_key_loc, \"r\") as credentials:\n",
    "            creds = json.load(credentials)\n",
    "            api_key = creds[\"dev_api_key\"]\n",
    "            lol_watcher = LolWatcher(creds[\"dev_api_key\"])\n",
    "            try:\n",
    "                # Validate API key by using it to check server status\n",
    "                lol_watcher.data_dragon.versions_all()\n",
    "                # Break if key is functional\n",
    "                break\n",
    "            except ApiError as error:\n",
    "                # If the current API key does not work input new one\n",
    "                if error.response.status_code == 403:\n",
    "                    new_api_key = input(\"API key is incorrect, enter correct key here.\")\n",
    "                    creds[\"dev_api_key\"] = new_api_key\n",
    "                    # Replace the old API key\n",
    "                    with open(api_key_loc, \"w\") as json_data:\n",
    "                        json.dump(creds, json_data)\n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_patch_time(reg, patch_nr=\"now\"):\n",
    "    \"\"\"\n",
    "    Read the patch number and return the time adjusted for time shift caused by different timezones.  \n",
    "    Args:\n",
    "        reg (str): Official registered Riot server that hosts league of legends.\n",
    "        patch_nr (str): League of legends update patch number. \n",
    "            Defaults to \"now\" which is the current time.\n",
    "    Returns:\n",
    "        adj_time (long): Time in (milli)seconds following the Coordinated Universal Time (UTC) format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read patch data\n",
    "    patch_loc = proj_dir / \"data\" / \"patches.json\"\n",
    "    with open(patch_loc, \"r\") as in_file:\n",
    "        patch_data = json.load(in_file)\n",
    "    \n",
    "    # Set the base utc time\n",
    "    if patch_nr == \"now\":\n",
    "        patch_time = int(datetime.utcnow().timestamp())\n",
    "    else:\n",
    "        for patch in patch_data[\"patches\"]:\n",
    "            if patch[\"name\"] == patch_nr:\n",
    "                patch_time = patch[\"start\"]\n",
    "    # Check if patch number is valid\n",
    "    assert patch_time, f\"Patch number: {patch_nr} is unknown\"\n",
    "\n",
    "    # Set the time shift\n",
    "    try:\n",
    "        reg_shifts = patch_data[\"shifts\"][reg.upper()]\n",
    "    except KeyError:\n",
    "        # Check if region provided is valid\n",
    "        raise KeyError(f\"Region: {reg} is unknown\")\n",
    "    \n",
    "    # Calculate time adjusted for the time shift of the region\n",
    "    adj_time = patch_time + reg_shifts\n",
    "    return adj_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_reg(reg_abbrv):\n",
    "    \"\"\"\n",
    "    Translate a league of legends region into a region readable by riot watcher.\n",
    "    \n",
    "    Args:\n",
    "        reg_abbrv (str): Abbreviation of a official registered Riot servers that\n",
    "            hosts league of legends (e.g. euw1).\n",
    "    Returns:\n",
    "        rw_region (str): Riot Watcher region the reg_abbrv server falls under.\n",
    "    \"\"\"\n",
    "    # Look up in the list what the riot watcher region is for the given region abbreviation\n",
    "    regions_metadata = {\"br1\": \"americas\",\n",
    "                        \"eun1\": \"europe\",\n",
    "                        \"euw1\": \"europe\",\n",
    "                        \"jp1\": \"asia\",\n",
    "                        \"kr\": \"asia\",\n",
    "                        \"la1\": \"americas\",\n",
    "                        \"la2\": \"americas\",\n",
    "                        \"na1\": \"americas\",\n",
    "                        \"oc1\": \"americas\",\n",
    "                        \"tr1\": \"europe\",\n",
    "                        \"ru\": \"europe\"\n",
    "                        }\n",
    "\n",
    "    for reg, rw_reg in regions_metadata.items():\n",
    "        if reg_abbrv.lower() == reg:\n",
    "            rw_region = rw_reg\n",
    "    \n",
    "    return rw_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=1, min=5, max=60), stop=stop_after_attempt(10))\n",
    "def get_matches(reg, pid, s_time, e_time):\n",
    "    \"\"\"\n",
    "    Retrieve match IDs from a summoner within a given timeframe.\n",
    "\n",
    "    Args:\n",
    "        reg (str): Abbreviation of a official registered Riot servers that\n",
    "            hosts league of legends (e.g. euw1).\n",
    "        pid (str): An Encrypted globally unique identifyer for a summoner.\n",
    "        s_time (long): Start of a timeframe in (milli)seconds following\n",
    "            the Coordinated Universal Time (UTC) format.\n",
    "        e_time (long): end of a timeframe in (milli)seconds following\n",
    "            the Coordinated Universal Time (UTC) format.\n",
    "    Returns:\n",
    "        matches (list): League of legends match IDs in chronological order\n",
    "            starting with the most recent match.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve all match ID's between two time points\n",
    "    rw_reg = trans_reg(reg)\n",
    "    matches = lol_watcher.match.matchlist_by_puuid(region=rw_reg,\n",
    "                                                   puuid=pid,\n",
    "                                                   start_time=s_time,\n",
    "                                                   count=100,\n",
    "                                                   queue=420,\n",
    "                                                   end_time=e_time)\n",
    "    \n",
    "    # Geather more match IDs in case matches exceeds the standard limit of 100\n",
    "    while len(matches) % 100 == 0 and len(matches) != 0:\n",
    "        # Geather match details of earliest match\n",
    "        match_deets = lol_watcher.match.by_id(rw_reg, matches[-1])\n",
    "        # Start time of earliest match\n",
    "        early_g_start = int(str(match_deets[\"info\"]['gameCreation'])[:10])\n",
    "        # Select 100 matches previous to early_g_start  \n",
    "        match_add = lol_watcher.match.matchlist_by_puuid(region=rw_reg,\n",
    "                                                         puuid=pid,\n",
    "                                                         start_time=s_time,\n",
    "                                                         count=100,\n",
    "                                                         queue=420,\n",
    "                                                         end_time=early_g_start)\n",
    "        if len(match_add) == 0:\n",
    "            break\n",
    "        else:\n",
    "            matches.extend(match_add)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=1, min=5, max=60), stop=stop_after_attempt(10))\n",
    "def geather_data(puuid, matches):\n",
    "    \"\"\"\n",
    "    Geather summoner data from a match and chronology data of the match.\n",
    "    \n",
    "    Args:\n",
    "        puuid (str): An Encrypted globally unique identifyer for a summoner.\n",
    "        matches (list): League of legends match IDs in chronological order\n",
    "                        starting with the most recent match.  \n",
    "    Returns:\n",
    "        df_matches_data (df): Data geathered from matches of a summoner.\n",
    "    \"\"\"\n",
    "    \n",
    "    game_info = [\"gameCreation\", \"gameStartTimestamp\"]\n",
    "    keep_data = [\"puuid\", \"teamPosition\", \"kills\", \"assists\", \"deaths\", \n",
    "                 \"doubleKills\", \"tripleKills\", \"quadraKills\", \"pentaKills\", \n",
    "                 \"killingSprees\", \"largestKillingSpree\", \n",
    "                 \"gameEndedInEarlySurrender\", \"teamEarlySurrendered\", \"gameEndedInSurrender\",\n",
    "                 \"neutralMinionsKilled\", \"totalMinionsKilled\", \"teamId\", \"win\", \"timePlayed\"]\n",
    "\n",
    "    col_names = [\"match_id\", \"puuid\", \"pos\", \"kills\", \"assists\", \"deaths\", \n",
    "                 \"2_kills\", \"3_kills\", \"4_kills\", \"5_kills\", \n",
    "                 \"kill_spree\", \"max_kill_spree\", \n",
    "                 \"remake\", \"pre_15_surr\", \"game_surr\",\n",
    "                 \"neutral_kills\", \"minion_kills\", \"team_id\", \"win\",\n",
    "                 \"time_played\", \"game_make\", \"game_start\"]\n",
    "      \n",
    "    comp_data = []\n",
    "    # Geather match details\n",
    "    for match_id in matches:\n",
    "        reg = match_id.split(\"_\")[0].lower()\n",
    "        match_deets = lol_watcher.match.by_id(trans_reg(reg), match_id)\n",
    "\n",
    "        # Collect time data\n",
    "        time_data = dict((key, match_deets[\"info\"][key]) for key in game_info)\n",
    "\n",
    "        # Collect summoner data       \n",
    "        for part_info in match_deets[\"info\"][\"participants\"]:\n",
    "            if part_info[\"puuid\"] == puuid:\n",
    "                filt_data = dict((key, part_info[key]) for key in keep_data)\n",
    "        match_data = {\"match_id\": match_id} | filt_data | time_data\n",
    "        comp_data.append(match_data.values())\n",
    "    \n",
    "    # Store all data in a dataframe\n",
    "    df_matches_data = pd.DataFrame(comp_data, columns=col_names)\n",
    "\n",
    "    return df_matches_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_matches(matches_data, max_rest, min_streak):\n",
    "    \"\"\"\n",
    "    Filter matches based on rest time in between matches and number of matches played in a row.  \n",
    "    \n",
    "    Args:\n",
    "        matches_data (df): Data geathered from matches of a summoner.\n",
    "        max_rest (int): Rest time in between matches in miliseconds e.g. 3600000 = 1 hour.\n",
    "        min_streak (int): Minimum games played in a row with less then max_rest between.\n",
    "    Returns:\n",
    "        df_match_filt (df): Matches filtered based on minimum subsequent matches within\n",
    "            the maximum rest time in between the matches.\n",
    "    \"\"\"\n",
    "      \n",
    "    # Add rest time between previous and next match to base the filtering of on\n",
    "    df_match_filt = matches_data \n",
    "    df_match_filt[\"game_end\"] = df_match_filt.loc[:,[\"game_start\", \"time_played\"]].sum(axis=1)\n",
    "    df_match_filt[\"prev_game_end\"] = df_match_filt[\"game_end\"].shift(-1, fill_value=np.nan)\n",
    "    df_match_filt[\"next_game_make\"] = df_match_filt[\"game_make\"].shift(1, fill_value=np.nan)\n",
    "    df_match_filt[\"time_since_last\"] = df_match_filt[\"game_make\"] - df_match_filt[\"prev_game_end\"]\n",
    "    df_match_filt[\"time_till_next\"] = df_match_filt[\"next_game_make\"] - df_match_filt[\"game_end\"]\n",
    "    \n",
    "    # Filter for matches based on rest time below the max_rest time\n",
    "    # Temporarily store if the game ID should be kept if rest time is below max_rest\n",
    "    df_match_filt['keep'] = np.where((df_match_filt['time_since_last'] <= max_rest) | (df_match_filt['time_till_next'] <= max_rest), True, False)\n",
    "    # Find games that were played in a streak by grouping based on matches played subsequently \n",
    "    game_streak = df_match_filt['keep'].diff().ne(0).cumsum()\n",
    "    # Drop streaks that are lower then min_streak\n",
    "    df_match_filt = df_match_filt[df_match_filt['keep'].groupby(game_streak).transform(\"count\") >= min_streak]\n",
    "    # Drop matches with rest times above max_rest \n",
    "    df_match_filt = df_match_filt[~(df_match_filt[\"keep\"] == 0.0)]\n",
    "    # Remove the keep column \n",
    "    df_match_filt.drop(\"keep\", axis=1, inplace = True)\n",
    "    \n",
    "    return df_match_filt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summoner_data(regs, tiers, divs, sum_lim, p_patch, r_patch, max_rest, min_streak, sumo_data_loc):\n",
    "    \"\"\"\n",
    "    Get puuid's, tier and division, from all regions that are in ranks below master rank ((random?) above bronze?).\n",
    "    \n",
    "    Args:\n",
    "        regs (list): Official registered Riot servers that hosts league of legends.\n",
    "        tier (list): Tiers below Master rank.\n",
    "        divs (list): Divisions in roman numerals.\n",
    "        sum_lim (int): Maximum number of summoner ids to collect per region, tier and division.\n",
    "        p_patch (str): A patch prior to then r_patch's patch.\n",
    "        r_patch (str): A more recent patch then p_patch's patch.\n",
    "        max_rest (int): Rest time in between matches in miliseconds e.g. 3600000 = 1 hour.\n",
    "        min_streak (int): Minimum games played in a row with less then max_rest between.\n",
    "        sumo_data_loc (str): location to store the info on the summoner and game statistics.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    for reg, tier, div in itertools.product(regs, tiers, divs):\n",
    "        summs_div = 0\n",
    "        page_nr = 0\n",
    "        # Keep adding new summoners until the summoner limit has been reached\n",
    "        while summs_div < sum_lim:\n",
    "            page_nr += 1\n",
    "            summs = lol_watcher.league.entries(reg, \"RANKED_SOLO_5x5\", tier, div, page_nr)\n",
    "            # Look into data per summoner\n",
    "            for sumo in summs:\n",
    "                if summs_div < sum_lim:\n",
    "                    # Get PUUID\n",
    "                    pid = lol_watcher.summoner.by_id(reg, sumo[\"summonerId\"])[\"puuid\"]\n",
    "\n",
    "                    # Retrieve all match ID's between two time points\n",
    "                    match_ids = get_matches(reg, pid, adj_patch_time(reg, p_patch), adj_patch_time(reg, r_patch))\n",
    "                    # Skip summoners that have no matches in the given time frame \n",
    "                    if not match_ids:\n",
    "                        continue\n",
    "        \n",
    "                    # Geather match data of the summoner\n",
    "                    match_info = geather_data(pid, match_ids)\n",
    "\n",
    "                    # Filter matches\n",
    "                    filt_match_info = filt_matches(match_info, max_rest, min_streak)\n",
    "                    # Skip summoners that have no matches left after filtering\n",
    "                    if filt_match_info.empty:\n",
    "                        continue\n",
    "                    \n",
    "                    # Add summoner rank information \n",
    "                    cur_rank = f\"{tier}_{div}\"\n",
    "                    filt_match_info.insert (2, \"rank\", cur_rank)\n",
    "\n",
    "                    # Increase the summoner counter\n",
    "                    summs_div += 1\n",
    "                    \n",
    "                    # Store summoner data in a tsv file\n",
    "                    file_true = sumo_data_loc.exists()\n",
    "                    filt_match_info.to_csv(sumo_data_loc,\n",
    "                                           header=not file_true,\n",
    "                                           mode=\"a\" if file_true else \"w\",\n",
    "                                           sep=\"\\t\",\n",
    "                                           index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df_match_filt, out_file):\n",
    "    \"\"\"\n",
    "    Preprocess the df_match_filt, manipulation and dropping some data to make to ready for use.  \n",
    "    \n",
    "    Args:\n",
    "        df_match_filt (df): Matches filtered based on minimum subsequent matches within\n",
    "            the maximum rest time in between the matches.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Add the streak id to the df_match_prep to follow win chance\n",
    "    streak_id = df_match_filt[\"win\"].ne(df_match_filt[\"win\"].shift()).cumsum()\n",
    "    df_match_filt[\"consecutive_wl\"] = df_match_filt.groupby(streak_id).cumcount()\n",
    "    df_match_filt.loc[df_match_filt.loc[:, \"win\"] == False, \"consecutive_wl\":] *= -1\n",
    "\n",
    "    \n",
    "    # Clean up the dataframe\n",
    "    # TODO: what other columns can be removed? prev_game_end, next_game_make\n",
    "    # TODO: remove all values that are above max rest? or is there value in keeping it?\n",
    "\n",
    "    # Drop the old index column\n",
    "    df_match_filt.drop(df_match_filt.columns[[0]], axis=1, inplace = True)\n",
    "\n",
    "    # TODO: TMP save for easy lookup\n",
    "    # Write out\n",
    "    df_match_filt.to_csv(out_file,\n",
    "                         mode=\"w\",\n",
    "                         sep=\"\\t\",\n",
    "                         index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory locations\n",
    "\n",
    "# Project folders\n",
    "proj_dir = Path.cwd().parent\n",
    "\n",
    "# Raw data storage\n",
    "data_dir = proj_dir / \"data\"\n",
    "\n",
    "# Out dir\n",
    "out_dir = proj_dir / \"out\"\n",
    "\n",
    "# Gobal variables\n",
    "\n",
    "# Set API key\n",
    "api_key_loc = data_dir / \"dev_api_key.json\"\n",
    "\n",
    "# Enter API key\n",
    "lol_watcher = LolWatcher(api_key(api_key_loc))\n",
    "\n",
    "# Read user settings\n",
    "settings_loc = proj_dir / \"settings\" / \"config.json\"\n",
    "with open(settings_loc, \"r\") as settings_data:\n",
    "    settings = json.load(settings_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the summoner info of n summoners\n",
    "\n",
    "# Remove output file if it exists\n",
    "raw_sumo_data = data_dir / \"summoner_data_raw.tsv\"\n",
    "\n",
    "while Path(raw_sumo_data).exists():\n",
    "    answer = input(\"\"\"Enter \"yes\" to overwrite file, or enter new filepath\"\"\")\n",
    "    if answer.upper() in [\"Y\", \"YES\"]:\n",
    "        os.remove(raw_sumo_data)\n",
    "    else:\n",
    "        raw_sumo_data = answer\n",
    "        touch(raw_sumo_data)\n",
    "        \n",
    "get_summoner_data(regs=settings[\"regions\"],\n",
    "                  tiers=settings[\"tiers\"],\n",
    "                  divs=settings['divisions'],\n",
    "                  sum_lim=settings['summoner_limit'],\n",
    "                  p_patch=settings[\"prior_patch\"],\n",
    "                  r_patch=settings[\"recent_patch\"],\n",
    "                  max_rest=settings[\"max_rest\"],\n",
    "                  min_streak=settings[\"min_streak\"],\n",
    "                  sumo_data_loc=raw_sumo_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>puuid</th>\n",
       "      <th>rank</th>\n",
       "      <th>pos</th>\n",
       "      <th>kills</th>\n",
       "      <th>assists</th>\n",
       "      <th>deaths</th>\n",
       "      <th>2_kills</th>\n",
       "      <th>3_kills</th>\n",
       "      <th>4_kills</th>\n",
       "      <th>...</th>\n",
       "      <th>win</th>\n",
       "      <th>time_played</th>\n",
       "      <th>game_make</th>\n",
       "      <th>game_start</th>\n",
       "      <th>game_end</th>\n",
       "      <th>prev_game_end</th>\n",
       "      <th>next_game_make</th>\n",
       "      <th>time_since_last</th>\n",
       "      <th>time_till_next</th>\n",
       "      <th>consecutive_wl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EUW1_5455184136</td>\n",
       "      <td>h38FAhzMqPzYu0QCT25UAxZUdjdLY1B5aOdGxdKjzPOE_S...</td>\n",
       "      <td>SILVER_I</td>\n",
       "      <td>JUNGLE</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2351</td>\n",
       "      <td>1631304112000</td>\n",
       "      <td>1631304262716</td>\n",
       "      <td>1631304265067</td>\n",
       "      <td>1.631303e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1608471.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUW1_5454920404</td>\n",
       "      <td>h38FAhzMqPzYu0QCT25UAxZUdjdLY1B5aOdGxdKjzPOE_S...</td>\n",
       "      <td>SILVER_I</td>\n",
       "      <td>TOP</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1304</td>\n",
       "      <td>1631302450000</td>\n",
       "      <td>1631302502225</td>\n",
       "      <td>1631302503529</td>\n",
       "      <td>1.631300e+12</td>\n",
       "      <td>1.631304e+12</td>\n",
       "      <td>2339875.0</td>\n",
       "      <td>1608471.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EUW1_5454983514</td>\n",
       "      <td>h38FAhzMqPzYu0QCT25UAxZUdjdLY1B5aOdGxdKjzPOE_S...</td>\n",
       "      <td>SILVER_I</td>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1946</td>\n",
       "      <td>1631300047000</td>\n",
       "      <td>1631300108179</td>\n",
       "      <td>1631300110125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.631302e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2339875.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUW1_5414939600</td>\n",
       "      <td>qZHgkSP20VlVqICoXMoFpVDfFk8NV54naBnTqgPEZN6GYV...</td>\n",
       "      <td>SILVER_I</td>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1563</td>\n",
       "      <td>1629023546000</td>\n",
       "      <td>1629023615267</td>\n",
       "      <td>1629023616830</td>\n",
       "      <td>1.629022e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1875411.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUW1_5414956170</td>\n",
       "      <td>qZHgkSP20VlVqICoXMoFpVDfFk8NV54naBnTqgPEZN6GYV...</td>\n",
       "      <td>SILVER_I</td>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1524</td>\n",
       "      <td>1629021469000</td>\n",
       "      <td>1629021669065</td>\n",
       "      <td>1629021670589</td>\n",
       "      <td>1.629019e+12</td>\n",
       "      <td>1.629024e+12</td>\n",
       "      <td>2692971.0</td>\n",
       "      <td>1875411.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          match_id                                              puuid  \\\n",
       "0  EUW1_5455184136  h38FAhzMqPzYu0QCT25UAxZUdjdLY1B5aOdGxdKjzPOE_S...   \n",
       "1  EUW1_5454920404  h38FAhzMqPzYu0QCT25UAxZUdjdLY1B5aOdGxdKjzPOE_S...   \n",
       "2  EUW1_5454983514  h38FAhzMqPzYu0QCT25UAxZUdjdLY1B5aOdGxdKjzPOE_S...   \n",
       "3  EUW1_5414939600  qZHgkSP20VlVqICoXMoFpVDfFk8NV54naBnTqgPEZN6GYV...   \n",
       "4  EUW1_5414956170  qZHgkSP20VlVqICoXMoFpVDfFk8NV54naBnTqgPEZN6GYV...   \n",
       "\n",
       "       rank     pos  kills  assists  deaths  2_kills  3_kills  4_kills  ...  \\\n",
       "0  SILVER_I  JUNGLE      5       26       6        0        0        0  ...   \n",
       "1  SILVER_I     TOP      5        6       3        1        0        0  ...   \n",
       "2  SILVER_I  MIDDLE      4        7       3        1        0        0  ...   \n",
       "3  SILVER_I  MIDDLE     16        7       5        3        1        0  ...   \n",
       "4  SILVER_I  MIDDLE      4        1       6        0        0        0  ...   \n",
       "\n",
       "     win  time_played      game_make     game_start       game_end  \\\n",
       "0  False         2351  1631304112000  1631304262716  1631304265067   \n",
       "1   True         1304  1631302450000  1631302502225  1631302503529   \n",
       "2   True         1946  1631300047000  1631300108179  1631300110125   \n",
       "3   True         1563  1629023546000  1629023615267  1629023616830   \n",
       "4  False         1524  1629021469000  1629021669065  1629021670589   \n",
       "\n",
       "   prev_game_end  next_game_make  time_since_last  time_till_next  \\\n",
       "0   1.631303e+12             NaN        1608471.0             NaN   \n",
       "1   1.631300e+12    1.631304e+12        2339875.0       1608471.0   \n",
       "2            NaN    1.631302e+12              NaN       2339875.0   \n",
       "3   1.629022e+12             NaN        1875411.0             NaN   \n",
       "4   1.629019e+12    1.629024e+12        2692971.0       1875411.0   \n",
       "\n",
       "   consecutive_wl  \n",
       "0               0  \n",
       "1               0  \n",
       "2               1  \n",
       "3               2  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: if this gets to slow it might be smarter to consider storing the data as a pickle object instead of a csv file\n",
    "# Read in the summoner data\n",
    "sumo_info = pd.read_csv(raw_sumo_data, sep = \"\\t\")\n",
    "\n",
    "# Preprocessing\n",
    "sumo_data_loc = out_dir / \"prep_sumo_data.tsv\"\n",
    "prep_data(sumo_info, sumo_data_loc)\n",
    "\n",
    "sumo_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "consecutive_wl\n",
       "-1    0.000000\n",
       " 0    0.461538\n",
       " 1    1.000000\n",
       " 2    1.000000\n",
       "Name: win, dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Base lines\n",
    "\n",
    "# Win rate per rank\n",
    "sumo_info.groupby(\"rank\")[\"win\"].mean()\n",
    "\n",
    "# Win rate \n",
    "sumo_info.groupby('consecutive_wl')[\"win\"].mean()\n",
    "\n",
    "# Add streaks\n",
    "# sumo_info.groupby(\"rank\")['win'].mean()\n",
    "\n",
    "\n",
    "# sumo_info[[\"win\", \"consecutive WL\"]]\n",
    "# base line = all games of a player\n",
    "# tilt is calculated as win % er streak increase or decrease\n",
    "# % win on first game\n",
    "# % win on secoond game\n",
    "# % win on third game etc\n",
    "\n",
    "# make 2 datasets games long rest, games short rest \n",
    "# long rest >\n",
    "# short rest <=\n",
    "# \n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance of rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REst time vs win rate plot\n",
    "# \n",
    "# check if player has games with short rest take all games fitler is done later in data analysis\n",
    "# \n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHen to players play? \n",
    "# player to time point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tilt or in the zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winrate increase or decrease by factor of previous game\n",
    "# base winrate?\n",
    "# define good and bad stats using medians/average normal dist? \n",
    "# Win rate in next game after losing with bad stats\n",
    "# Win rate in next game after losing with good stats\n",
    "# Win rate in next game after winning with bad stats\n",
    "# Win rate in next game after winning with good stats\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86fe447469a8d852eea4b65c790d87be74d102a869903b8cc8b4ce651f2c3448"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tilt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
