{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TILT - Teemo Induced Loss of Tranquility\n",
    "A research project to study main factors in inducing tilt.\n",
    "\n",
    "ONLY LOOKS AT THE PERSON STATS THEMSELVES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "from pathlib2 import Path\n",
    "from riotwatcher import LolWatcher, ApiError\n",
    "\n",
    "# import arrow\n",
    "# import csv\n",
    "import itertools\n",
    "# import datetime\n",
    "# import time\n",
    "import json\n",
    "# import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import roleml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def api_key(api_key_loc):\n",
    "    \"\"\"\n",
    "    Read in the development API key from a file and checks if it is viable.\n",
    "    \n",
    "    Args:\n",
    "        credentials (str): Name of json file containing the credentials.\n",
    "    Returns:\n",
    "        api_key (str): The API key.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        with open(api_key_loc, \"r\") as json_data:\n",
    "            creds = json.load(json_data)\n",
    "            api_key = creds[\"dev_api_key\"]\n",
    "            lol_watcher = LolWatcher(creds[\"dev_api_key\"])\n",
    "            try:\n",
    "                # Validate API key by using it to check server status\n",
    "                lol_watcher.lol_status.shard_data(\"euw1\")\n",
    "                # Break if key is functional\n",
    "                break\n",
    "            except ApiError as error:\n",
    "                # If the current API key does not work input new one\n",
    "                if error.response.status_code == 403:\n",
    "                    new_api_key = input(\"API key is incorrect, enter correct key here.\")\n",
    "                    creds[\"dev_api_key\"] = new_api_key\n",
    "                    # Replace the old API key\n",
    "                    with open(api_key_loc, \"w\") as json_data:\n",
    "                        json.dump(creds, json_data)\n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_reg(reg_abbrv):\n",
    "    \"\"\"\n",
    "    Translate a league of legends region into a region readable by riot watcher.\n",
    "    \n",
    "    Args:\n",
    "        reg_abbrv (str): Abbreviation of a official registered Riot servers that\n",
    "                         hosts league of legends (e.g. euw1).\n",
    "    Returns:\n",
    "        rw_region (str): Riot Watcher region the reg_abbrv server falls under.\n",
    "    \"\"\"\n",
    "    # Look up in the list what the riot watcher region is for the given region abbreviation\n",
    "    regions_metadata = {\"br1\": \"americas\",\n",
    "                        \"eun1\": \"europe\",\n",
    "                        \"euw1\": \"europe\",\n",
    "                        \"jp1\": \"asia\",\n",
    "                        \"kr\": \"asia\",\n",
    "                        \"la1\": \"americas\",\n",
    "                        \"la2\": \"americas\",\n",
    "                        \"na1\": \"americas\",\n",
    "                        \"oc1\": \"americas\",\n",
    "                        \"tr1\": \"europe\",\n",
    "                        \"ru\": \"europe\"\n",
    "                        }\n",
    "\n",
    "    for reg, rw_reg in regions_metadata.items():\n",
    "        if reg_abbrv.lower() == reg:\n",
    "            rw_region = rw_reg\n",
    "    \n",
    "    return rw_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(reg, pid, s_time, e_time):\n",
    "    \"\"\"\n",
    "    Retrieve match IDs from a summoner within a given timeframe.\n",
    "\n",
    "    Args:\n",
    "        reg (str): Abbreviation of a official registered Riot servers that\n",
    "                   hosts league of legends (e.g. euw1).\n",
    "        pid (str): An Encrypted globally unique identifyer for a summoner.\n",
    "        s_time (long): Start of a timeframe in (milli)seconds following\n",
    "                       the Coordinated Universal Time (UTC) format.\n",
    "        e_time (long): end of a timeframe in (milli)seconds following\n",
    "                       the Coordinated Universal Time (UTC) format.\n",
    "    Returns:\n",
    "        matches (list): League of legends match IDs in chronological order\n",
    "                        starting with the most recent match.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve all match ID's between two time points \n",
    "    matches = lol_watcher.match.matchlist_by_puuid(region=trans_reg(reg),\n",
    "                                                   puuid=pid,\n",
    "                                                   start_time=s_time,\n",
    "                                                   end_time=e_time,\n",
    "                                                   count=100)\n",
    "    \n",
    "    # Geather more match IDs in case matches exceeds the standard limit of 100\n",
    "    while len(matches) % 100 == 0 and len(matches) != 0:\n",
    "        # Geather match details of earliest match\n",
    "        match_deets = lol_watcher.match.by_id(trans_reg(reg), matches[-1])\n",
    "        # Start time of earliest match\n",
    "        early_g_start = int(str(match_deets[\"info\"]['gameCreation'])[:10])\n",
    "        # Select 100 matches previous to early_g_start  \n",
    "        match_add = lol_watcher.match.matchlist_by_puuid(region=trans_reg(reg),\n",
    "                                                         puuid=pid,\n",
    "                                                         start_time=s_time,\n",
    "                                                         end_time=early_g_start,\n",
    "                                                         count=100)\n",
    "        if len(match_add) == 0:\n",
    "            break\n",
    "        else:\n",
    "            matches.extend(match_add)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geather_data(puuid, matches):\n",
    "    \"\"\"\n",
    "    Geather summoner data from a match and chronology data of the match.\n",
    "    \n",
    "    Args:\n",
    "        puuid (str): An Encrypted globally unique identifyer for a summoner.\n",
    "        matches (list): League of legends match IDs in chronological order\n",
    "                        starting with the most recent matches.  \n",
    "    Returns:\n",
    "        df_matches_data (df): Data geathered from matches of a summoner.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_info = [\"gameCreation\", \"gameStartTimestamp\", \"gameDuration\"]\n",
    "    keep_data = [\"puuid\", \"kills\", \"assists\", \"deaths\", \n",
    "                 \"doubleKills\", \"tripleKills\", \"quadraKills\", \"pentaKills\", \n",
    "                 \"killingSprees\", \"largestKillingSpree\", \n",
    "                 \"teamEarlySurrendered\", \"gameEndedInEarlySurrender\", \"gameEndedInSurrender\",\n",
    "                 \"neutralMinionsKilled\", \"totalMinionsKilled\", \"teamId\", \"win\"]\n",
    "\n",
    "    col_names = [\"match_id\", \"puuid\", \"kills\", \"assists\", \"deaths\", \n",
    "                 \"2_kills\", \"3_kills\", \"4_kills\", \"5_kills\", \n",
    "                 \"kill_spree\", \"max_kill_spree\", \n",
    "                 \"early_surr_try\", \"early_surr\", \"game_surr\",\n",
    "                 \"neutral_kills\", \"mini_kills\", \"team_id\", \"win\",\n",
    "                 \"game_make\", \"game_start\", \"game_dur\"]\n",
    "      \n",
    "    comp_data = []\n",
    "    # Geather match details\n",
    "    for match_id in matches:\n",
    "        reg = match_id.split(\"_\")[0].lower()\n",
    "        match_deets = lol_watcher.match.by_id(trans_reg(reg), match_id)        \n",
    "        # Collect time data\n",
    "        time_data = dict((key, match_deets[\"info\"][key]) for key in time_info)\n",
    "\n",
    "        # Collect summoner data       \n",
    "        for part_info in match_deets[\"info\"][\"participants\"]:\n",
    "            if part_info[\"puuid\"] == puuid:\n",
    "                filt_data = dict((key, part_info[key]) for key in keep_data)\n",
    "        match_data = {\"match_id\": match_id} | filt_data | time_data\n",
    "        comp_data.append(match_data.values())\n",
    "    \n",
    "    # Store all data in a dataframe\n",
    "    df_matches_data = pd.DataFrame(comp_data, columns=col_names)\n",
    "\n",
    "    return df_matches_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_matches(matches_data, max_rest, min_streak):\n",
    "    \"\"\"\n",
    "    Filter matches based on rest time in between matches and number of matches played in a row.  \n",
    "    \n",
    "    Args:\n",
    "        matches_data (df): Data geathered from matches of a summoner.\n",
    "        max_rest (int): Rest time in between matches in miliseconds e.g. 3600000 = 1 hour.\n",
    "        min_streak (int): Minimum games played in a row with less then max_rest between.\n",
    "    Returns:\n",
    "        df_match_filt (df): Matches filtered based on minuum subsequent matches within\n",
    "                            the maximum rest time in between the matches.\n",
    "    \"\"\"\n",
    "      \n",
    "    # Filter for matches based on rest time\n",
    "\n",
    "    # Add rest time\n",
    "    df_match_filt = matches_data \n",
    "    df_match_filt[\"game_end\"] = df_match_filt.loc[:,[\"game_start\", \"game_dur\"]].sum(axis=1)\n",
    "    df_match_filt[\"prev_game_make\"] = df_match_filt[\"game_make\"].shift(-1, fill_value=0)\n",
    "    df_match_filt[\"rest_time\"] = df_match_filt[\"game_end\"] - df_match_filt[\"prev_game_make\"]\n",
    "\n",
    "\n",
    "    # Store if the game ID should be kept if rest time is below max_rest\n",
    "    df_match_filt['keep'] = df_match_filt[\"rest_time\"] <= max_rest\n",
    "    # Grouping based on matches played subsequently \n",
    "    subseq_true = df_match_filt['keep'].diff().ne(0).cumsum()\n",
    "    # Drop streaks that are lower then min_streak\n",
    "    df_match_filt = df_match_filt[df_match_filt['keep'].groupby(subseq_true).transform(\"count\") >= min_streak]\n",
    "    # Drop matches with rest times above max_rest \n",
    "    df_match_filt = df_match_filt[~(df_match_filt[\"keep\"] == 0.0)]\n",
    "\n",
    "    # Add the streak id to the df_match_filt\n",
    "    df_match_filt[\"streak_id\"] = df_match_filt.groupby(subseq_true).grouper.group_info[0]\n",
    "\n",
    "    # Remove the keep column \n",
    "    df_match_filt.drop(\"keep\", axis=1, inplace = True)\n",
    "    \n",
    "    return df_match_filt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=\"EUW1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_role(df_match_filt):\n",
    "    \"\"\"\n",
    "    Filter matches based on rest time in between matches and number of matches played in a row.  \n",
    "    \n",
    "    Args:\n",
    "        df_match_filt (df): Matches filtered based on minuum subsequent matches within\n",
    "                            the maximum rest time in between the matches.\n",
    "    Returns:\n",
    "        df_match (df): df_match_filt with added in game role of player.\n",
    "    \"\"\"\n",
    "    \n",
    "    roles=[]\n",
    "    for match_id, puuid in zip(df_match_filt['match_id'], df_match_filt['puuid']):\n",
    "        match = lol_watcher.match.by_id(trans_reg(reg), match_id)\n",
    "        match_deets = match[\"metadata\"] | match[\"info\"]\n",
    "        match_time_line = lol_watcher.match.timeline_by_match(trans_reg(reg), match_id)\n",
    "        # print(match_deets)\n",
    "        print(roleml.predict(match_deets, match_time_line))  \n",
    "        # print(match_id, puuid)\n",
    "    \n",
    "\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "IncorrectMap",
     "evalue": "This package only handles Summoner’s Rift games.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIncorrectMap\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-c3218f719b24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf_match_filt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgeather_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PkyDyFsJQ35GQYruyFBfALnEvWKhRNSPqNyq15L6wgmY4WWH_ddk1ufUMtNh2-ioNtJvHwo-aY3c-w\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EUW1_5395088971'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpred_role\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_match_filt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-1b5363986460>\u001b[0m in \u001b[0;36mpred_role\u001b[1;34m(df_match_filt)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mmatch_time_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlol_watcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeline_by_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans_reg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# print(match_deets)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroleml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch_deets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch_time_line\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m# print(match_id, puuid)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\rito_games\\lib\\site-packages\\roleml\\roleml.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(match, timeline, cassiopeia_dicts)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMatchTooShort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mapId\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncorrectMap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcassiopeia_dicts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIncorrectMap\u001b[0m: This package only handles Summoner’s Rift games."
     ]
    }
   ],
   "source": [
    "# result = [pred_role(match_id, puuid) for match_id, puuid in zip(df_match_filt['match_id'], df_match_filt['puuid'])]\n",
    "df_match_filt=geather_data(\"PkyDyFsJQ35GQYruyFBfALnEvWKhRNSPqNyq15L6wgmY4WWH_ddk1ufUMtNh2-ioNtJvHwo-aY3c-w\",['EUW1_5395088971'])\n",
    "\n",
    "pred_role(df_match_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_summoner_data(regs, tiers, divs, sum_lim, s_time, e_time, max_rest, min_streak, sumo_data_out):\n",
    "    \"\"\"\n",
    "    Get puuid's, tier and division, from all regions that are in ranks below master rank ((random?) above bronze?).\n",
    "    \n",
    "    Args:\n",
    "        regs (list): Official registered Riot servers that hosts league of legends.\n",
    "        tier (list): Tiers below Master rank.\n",
    "        divs (list): Divisions in roman numerals.\n",
    "        sum_lim (int): Maximum number of summoner ids to collect per region, tier and division\n",
    "        s_time (long): Start of a timeframe in (milli)seconds following\n",
    "                       the Coordinated Universal Time (UTC) format.\n",
    "        e_time (long): end of a timeframe in (milli)seconds following\n",
    "                       the Coordinated Universal Time (UTC) format.\n",
    "        max_rest (int): Rest time in between matches in miliseconds e.g. 3600000 = 1 hour.\n",
    "        min_streak (int): Minimum games played in a row with less then max_rest between.\n",
    "        sumo_data_out (str): location to store the info on the summoner and game statistics.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # for reg, tier, div in itertools.product(regs, tiers, divs): # real line change what we want in the settings file\n",
    "    for reg, tier, div in itertools.product(regs, tiers, divs[0:1]): # test line\n",
    "        # print(reg, tier, div) # TODO: remove me later\n",
    "        summs_div = 0\n",
    "        page_nr = 0\n",
    "        # Keep adding new summoners until the summoner limit has been reached\n",
    "        while summs_div < sum_lim:\n",
    "            page_nr += 1\n",
    "            summs = lol_watcher.league.entries(reg, \"RANKED_SOLO_5x5\", tier, div, page_nr)\n",
    "            # Look into data per summoner\n",
    "            for sumo in summs:\n",
    "                if summs_div < sum_lim:\n",
    "                    # Get PUUID\n",
    "                    pid = lol_watcher.summoner.by_id(reg, sumo[\"summonerId\"])[\"puuid\"]\n",
    "\n",
    "                    # Retrieve all match ID's between two time points\n",
    "                    match_ids = get_matches(reg, pid, s_time, e_time)\n",
    "                    # Skip summoners that have no matches in the given time frame \n",
    "                    if not match_ids:\n",
    "                        continue\n",
    "        \n",
    "                    # Geather match data of the summoner\n",
    "                    match_info = geather_data(pid, match_ids)\n",
    "\n",
    "                    # Filter matches\n",
    "                    filt_match_info = filt_matches(match_info, max_rest, min_streak)\n",
    "                    # Skip summoners that have no matches left after filtering\n",
    "                    if filt_match_info.empty:\n",
    "                        continue\n",
    "                    \n",
    "                    \n",
    "                    # Add summoner rank information \n",
    "                    cur_rank = f\"{tier}_{div}\"\n",
    "                    filt_match_info.insert (2, \"rank\", cur_rank)\n",
    "\n",
    "                    # Increase the summoner counter\n",
    "                    summs_div += 1\n",
    "                    \n",
    "                    # Store summoner data in a tsv file\n",
    "                    file_true = sumo_data_out.exists()\n",
    "                    filt_match_info.to_csv(sumo_data_out,\n",
    "                                           header=not file_true,\n",
    "                                           mode='a' if file_true else 'w',\n",
    "                                           sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory locations\n",
    "\n",
    "# Project folders\n",
    "proj_dir = Path.cwd().parent\n",
    "\n",
    "# Raw data storage\n",
    "data_dir = proj_dir / \"data\"\n",
    "\n",
    "# Out dir\n",
    "out_dir = proj_dir / \"out\"\n",
    "\n",
    "# Gobal variables\n",
    "\n",
    "# Set API key\n",
    "api_key_loc = data_dir / \"dev_api_key.json\"\n",
    "\n",
    "# Enter API key\n",
    "lol_watcher = LolWatcher(api_key(api_key_loc))\n",
    "\n",
    "# Read user settings \n",
    "settings_loc = proj_dir / \"settings\" / \"config.json\"\n",
    "with open(settings_loc, \"r\") as settings_data:\n",
    "    settings = json.load(settings_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summs_div=1, pagenr=1\n",
      "summs_div=2, pagenr=1\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the summoner info of n summoners\n",
    "\n",
    "# Remove output file if it exists\n",
    "out_file_path = out_dir / \"summoner_data.tsv\"\n",
    "if out_file_path.exists():\n",
    "    os.remove(out_file_path)\n",
    "\n",
    "get_summoner_data(regs=settings[\"regions\"],\n",
    "                  tiers=settings[\"tiers\"],\n",
    "                  divs=settings['divisions'],\n",
    "                  sum_lim=settings['summoner_limit'],\n",
    "                  s_time=settings[\"start_time\"],\n",
    "                  e_time=settings[\"end_time\"],\n",
    "                  max_rest=settings[\"max_rest\"],\n",
    "                  min_streak=settings[\"min_streak\"],\n",
    "                  sumo_data_out=out_dir / \"summoner_data.tsv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Read in the summoner data\n",
    "# sumo_info = pd.read_csv(summs_data_out, sep = \"\\t\")\n",
    "\n",
    "\n",
    "# print(summs_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Use timeline data\n",
    "Finally, we can use most-match data in the timeline objects to identify the position on the map of the champions\n",
    "throughout the game. We can also look at items, runes, summoner spells, etc. to help narrow down what position\n",
    "the champion likely played in. This is easiest implemented using a machine learning approach. Training data can be\n",
    "found here: https://github.com/Canisback/roleML/blob/master/data/verification_results.csv. An implementation of an\n",
    "SVM (a machine learning model) to identify lanes and roles can be found here: https://github.com/meraki-analytics/\n",
    "role-identification/blob/timeline/timeline-roleidentification/finished_timeline_roleID.ipynb that you can use as an example for your own model. A decision tree is another good machine learning algorithm for this task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base line\n",
    "# base line = all games of a player\n",
    "# tilt is calculated as win % er streak increase or decrease\n",
    "# % win on first game\n",
    "# % win on secoond game\n",
    "# % win on third game etc\n",
    "\n",
    "# make 2 datasets games long rest, games short rest \n",
    "# long rest >\n",
    "# short rest <=\n",
    "# \n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance of rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REst time vs win rate plot\n",
    "# \n",
    "# check if player has games with short rest take all games fitler is done later in data analysis\n",
    "# \n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHen to players play? \n",
    "# player to time point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tilt or in the zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winrate increase or decrease by factor of previous game\n",
    "# base winrate?\n",
    "# define good and bad stats using medians/average normal dist? \n",
    "# Win rate in next game after losing with bad stats\n",
    "# Win rate in next game after losing with good stats\n",
    "# Win rate in next game after winning with bad stats\n",
    "# Win rate in next game after winning with good stats\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
