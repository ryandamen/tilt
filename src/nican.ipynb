{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TILT - Teemo Induced Loss of Tranquility\n",
    "A research project to study main factors in inducing tilt.\n",
    "\n",
    "ONLY LOOKS AT THE PERSON STATS THEMSELVES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "from pathlib2 import Path\n",
    "from riotwatcher import LolWatcher, ApiError\n",
    "\n",
    "\n",
    "# import arrow\n",
    "# import csv\n",
    "import itertools\n",
    "# import datetime\n",
    "# import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def api_key(api_key_loc):\n",
    "    \"\"\"\n",
    "    Read in the development API key from a file and checks if it is viable.\n",
    "    \n",
    "    Args:\n",
    "        credentials (str): Name of json file containing the credentials.\n",
    "    Returns:\n",
    "        api_key (str): The API key.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        with open(api_key_loc, \"r\") as json_data:\n",
    "            creds = json.load(json_data)\n",
    "            api_key = creds[\"dev_api_key\"]\n",
    "            lol_watcher = LolWatcher(creds[\"dev_api_key\"])\n",
    "            try:\n",
    "                # Validate API key by using it to check server status\n",
    "                lol_watcher.lol_status.shard_data(\"euw1\")\n",
    "                # Break if key is functional\n",
    "                break\n",
    "            except ApiError as error:\n",
    "                # If the current API key does not work input new one\n",
    "                if error.response.status_code == 403:\n",
    "                    new_api_key = input(\"API key is incorrect, enter correct key here.\")\n",
    "                    creds[\"dev_api_key\"] = new_api_key\n",
    "                    # Replace the old API key\n",
    "                    with open(api_key_loc, \"w\") as json_data:\n",
    "                        json.dump(creds, json_data)\n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_reg(reg_abbrv):\n",
    "    \"\"\"\n",
    "    Translate a league of legends region into a region readable by riot watcher.\n",
    "    \n",
    "    Args:\n",
    "        reg_abbrv (str): Abbreviation of a official registered Riot servers that\n",
    "                         hosts league of legends (e.g. euw1).\n",
    "    Returns:\n",
    "        rw_region (str): Riot Watcher region the reg_abbrv server falls under.\n",
    "    \"\"\"\n",
    "    # Look up in the list what the riot watcher region is for the given region abbreviation\n",
    "    regions_metadata = {\"br1\": \"americas\",\n",
    "                        \"eun1\": \"europe\",\n",
    "                        \"euw1\": \"europe\",\n",
    "                        \"jp1\": \"asia\",\n",
    "                        \"kr\": \"asia\",\n",
    "                        \"la1\": \"americas\",\n",
    "                        \"la2\": \"americas\",\n",
    "                        \"na1\": \"americas\",\n",
    "                        \"oc1\": \"americas\",\n",
    "                        \"tr1\": \"europe\",\n",
    "                        \"ru\": \"europe\"\n",
    "                        }\n",
    "\n",
    "    for reg, rw_reg in regions_metadata.items():\n",
    "        if reg_abbrv.lower() == reg:\n",
    "            rw_region = rw_reg\n",
    "    \n",
    "    return rw_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(reg, pid, s_time, e_time):\n",
    "    \"\"\"\n",
    "    Retrieve match IDs from a summoner within a given timeframe.\n",
    "\n",
    "    Args:\n",
    "        reg (str): Abbreviation of a official registered Riot servers that\n",
    "                   hosts league of legends (e.g. euw1).\n",
    "        pid (str): An Encrypted globally unique identifyer for a summoner.\n",
    "        s_time (long): Start of a timeframe in (milli)seconds following\n",
    "                       the Coordinated Universal Time (UTC) format.\n",
    "        e_time (long): end of a timeframe in (milli)seconds following\n",
    "                       the Coordinated Universal Time (UTC) format.\n",
    "    Returns:\n",
    "        matches (list): League of legends match IDs in chronological order\n",
    "                        starting with the most recent match.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve all match ID's between two time points \n",
    "    matches = lol_watcher.match.matchlist_by_puuid(region=trans_reg(reg),\n",
    "                                                   puuid=pid,\n",
    "                                                   start_time=s_time,\n",
    "                                                   end_time=e_time,\n",
    "                                                   count=100)\n",
    "    \n",
    "    # Geather more match IDs in case matches exceeds the standard limit of 100\n",
    "    while len(matches) % 100 == 0 and len(matches) != 0:\n",
    "        # Geather match details of earliest match\n",
    "        match_deets = lol_watcher.match.by_id(trans_reg(reg), matches[-1])\n",
    "        # Start time of earliest match\n",
    "        early_g_start = int(str(match_deets[\"info\"]['gameCreation'])[:10])\n",
    "        # Select 100 matches previous to early_g_start  \n",
    "        match_add = lol_watcher.match.matchlist_by_puuid(region=trans_reg(reg),\n",
    "                                                         puuid=pid,\n",
    "                                                         start_time=s_time,\n",
    "                                                         end_time=early_g_start,\n",
    "                                                         count=100)\n",
    "        if len(match_add) == 0:\n",
    "            break\n",
    "        else:\n",
    "            matches.extend(match_add)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geather_data(puuid, matches):\n",
    "    \"\"\"\n",
    "    Geather summoner data from a match and chronology data of the match.\n",
    "    \n",
    "    Args:\n",
    "        puuid (str): An Encrypted globally unique identifyer for a summoner.\n",
    "        matches (list): League of legends match IDs in chronological order\n",
    "                        starting with the most recent matches.  \n",
    "    Returns:\n",
    "        df_matches_data (df): Data geathered from matches of a summoner.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_info = [\"gameCreation\", \"gameStartTimestamp\", \"gameDuration\"]\n",
    "    keep_data = [\"puuid\", \"individualPosition\", \"role\", \"teamPosition\", \"lane\",\"kills\", \"assists\", \"deaths\", \n",
    "                 \"doubleKills\", \"tripleKills\", \"quadraKills\", \"pentaKills\", \n",
    "                 \"killingSprees\", \"largestKillingSpree\", \n",
    "                 \"teamEarlySurrendered\", \"gameEndedInEarlySurrender\", \"gameEndedInSurrender\",\n",
    "                 \"neutralMinionsKilled\", \"totalMinionsKilled\", \"teamId\", \"win\"]\n",
    "\n",
    "    col_names = [\"puuid\", \"match_id\", \"indiv_pos\", \"role\", \"team_pos\", \"lane\",\n",
    "                 \"kills\", \"assists\", \"deaths\", \n",
    "                 \"2_kills\", \"3_kills\", \"4_kills\", \"5_kills\", \n",
    "                 \"kill_spree\", \"max_kill_spree\", \n",
    "                 \"early_surr_try\", \"early_surr\", \"game_surr\",\n",
    "                 \"neutral_kills\", \"mini_kills\", \"team_id\", \"win\",\n",
    "                 \"game_make\", \"game_start\", \"game_dur\"]\n",
    "      \n",
    "    comp_data = []\n",
    "    # Geather match details\n",
    "    for match_id in matches:\n",
    "        reg = match_id.split(\"_\")[0].lower()\n",
    "        match_deets = lol_watcher.match.by_id(trans_reg(reg), match_id)        \n",
    "        # Collect time data\n",
    "        time_data = dict((key, match_deets[\"info\"][key]) for key in time_info)\n",
    "\n",
    "        # Collect summoner data       \n",
    "        for part_info in match_deets[\"info\"][\"participants\"]:\n",
    "            if part_info[\"puuid\"] == puuid:\n",
    "                filt_data = dict((key, part_info[key]) for key in keep_data)\n",
    "        match_data = {\"match_id\": match_id} | filt_data | time_data\n",
    "        comp_data.append(match_data.values())\n",
    "    \n",
    "    # Store all data in a dataframe\n",
    "    df_matches_data = pd.DataFrame(comp_data, columns=col_names)\n",
    "\n",
    "    return df_matches_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_matches(matches_data, max_rest, min_streak):\n",
    "    \"\"\"\n",
    "    Filter matches based on rest time in between matches and number of matches played in a row.  \n",
    "    \n",
    "    Args:\n",
    "        matches_data (df): Data geathered from matches of a summoner.\n",
    "        max_rest (int): Rest time in between matches in miliseconds e.g. 3600000 = 1 hour.\n",
    "        min_streak (int): Minimum games played in a row with less then max_rest between.\n",
    "    Returns:\n",
    "        df_match_filt (df): Matches filtered based on minuum subsequent matches within\n",
    "                            the maximum rest time in between the matches.\n",
    "    \"\"\"\n",
    "      \n",
    "    # Filter for matches based on rest time\n",
    "\n",
    "    # Add rest time\n",
    "    df_match_filt = matches_data \n",
    "    df_match_filt[\"game_end\"] = df_match_filt.loc[:,[\"game_start\", \"game_dur\"]].sum(axis=1)\n",
    "    df_match_filt[\"prev_game_make\"] = df_match_filt[\"game_make\"].shift(-1, fill_value=0)\n",
    "    df_match_filt[\"rest_time\"] = df_match_filt[\"game_end\"] - df_match_filt[\"prev_game_make\"]\n",
    "\n",
    "\n",
    "    # # Store if the game ID should be kept if rest time is below max_rest\n",
    "    # df_match_filt['keep'] = df_match_filt[\"rest_time\"] <= max_rest\n",
    "    # # Grouping based on matches played subsequently \n",
    "    # subseq_true = df_match_filt['keep'].diff().ne(0).cumsum()\n",
    "    # # Drop streaks that are lower then min_streak\n",
    "    # df_match_filt = df_match_filt[df_match_filt['keep'].groupby(subseq_true).transform(\"count\") >= min_streak]\n",
    "    # # Drop matches with rest times above max_rest \n",
    "    # df_match_filt = df_match_filt[~(df_match_filt[\"keep\"] == 0.0)]\n",
    "\n",
    "    # # Add the streak id to the df_match_filt\n",
    "    # df_match_filt[\"streak_id\"] = df_match_filt.groupby(subseq_true).grouper.group_info[0]\n",
    "\n",
    "    # # Remove the keep column \n",
    "    # df_match_filt.drop(\"keep\", axis=1, inplace = True)\n",
    "    \n",
    "    return df_match_filt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_summoner_data(regs, tiers, divs, sum_lim, s_time, e_time, max_rest, min_streak):\n",
    "    \"\"\"\n",
    "    Get puuid's, tier and division, from all regions that are in ranks below master rank ((random?) above bronze?).\n",
    "    \n",
    "    Args:\n",
    "        regs (list): Official registered Riot servers that hosts league of legends.\n",
    "        tier (list): Tiers below Master rank.\n",
    "        divs (list): Divisions in roman numerals.\n",
    "        sum_lim (int): Maximum number of summoner ids to collect per region, tier and division\n",
    "        s_time (long): Start of a timeframe in (milli)seconds following\n",
    "                       the Coordinated Universal Time (UTC) format.\n",
    "        e_time (long): end of a timeframe in (milli)seconds following\n",
    "                       the Coordinated Universal Time (UTC) format.\n",
    "        max_rest (int): Rest time in between matches in miliseconds e.g. 3600000 = 1 hour.\n",
    "        min_streak (int): Minimum games played in a row with less then max_rest between.\n",
    "    Returns:\n",
    "        sumo_info (df): Info on the summoner and game statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_summs_info = pd.DataFrame()\n",
    "    # for reg, tier, div in itertools.product(regs, tiers, divs): # real line change what we want in teh settings file\n",
    "    for reg, tier, div in itertools.product(regs[0:1], tiers[1:2], divs[0:1]): # test line\n",
    "        # print(reg, tier, div) # TODO: remove me later\n",
    "        summs_div = 0\n",
    "        page_nr = 0\n",
    "        # Keep adding new summoners until the summoner limit has been reached\n",
    "        while summs_div < sum_lim:\n",
    "            page_nr += 1\n",
    "            summs = lol_watcher.league.entries(reg, \"RANKED_SOLO_5x5\", tier, div, page_nr)\n",
    "            # Look into data per summoner\n",
    "            for sumo in summs:\n",
    "                if summs_div < sum_lim:\n",
    "                    # Get puuid\n",
    "                    pid = lol_watcher.summoner.by_id(reg, sumo[\"summonerId\"])[\"puuid\"]\n",
    "\n",
    "                    # Retrieve all match ID's between two time points\n",
    "                    match_ids = get_matches(reg, pid, s_time, e_time)\n",
    "                    # Skip summoners that have no matches in the given time frame \n",
    "                    if not match_ids:\n",
    "                        continue\n",
    "        \n",
    "                    # Geather match data of the summoner\n",
    "                    match_info = geather_data(pid, match_ids)\n",
    "\n",
    "                    # Filter matches\n",
    "                    filt_match_info = filt_matches(match_info, max_rest, min_streak)\n",
    "                    print(filt_match_info)\n",
    "                    # Skip summoners that have no matches left after filtering\n",
    "                    if not filt_match_info.empty:\n",
    "                        continue\n",
    "                    \n",
    "                    # Add summoner rank information \n",
    "                    cur_rank = f\"{tier}_{div}\"\n",
    "                    filt_match_info.insert (2, \"rank\", cur_rank)\n",
    "\n",
    "                    # Add the geather data to the main dataframe\n",
    "                    df_summs_info.append(filt_match_info, ignore_index = True)\n",
    "\n",
    "                    # If succesfull increase the summoner counter\n",
    "                    summs_div += 1\n",
    "\n",
    "            # If summoner limit has been reached return the data\n",
    "            if summs_div == sum_lim:\n",
    "                summs_info = df_summs_info\n",
    "                return(summs_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory locations\n",
    "\n",
    "# Project folders\n",
    "proj_dir = Path.cwd().parent\n",
    "\n",
    "# Raw data storage\n",
    "data_dir = proj_dir / \"data\"\n",
    "\n",
    "# Out dir\n",
    "out_dir = proj_dir / \"out\"\n",
    "\n",
    "# Gobal variables\n",
    "\n",
    "# Set API key\n",
    "api_key_loc = data_dir / \"dev_api_key.json\"\n",
    "\n",
    "# Enter API key\n",
    "lol_watcher = LolWatcher(api_key(api_key_loc))\n",
    "\n",
    "# Read user settings \n",
    "settings_loc = proj_dir / \"settings\" / \"config.json\"\n",
    "with open(settings_loc, \"r\") as settings_data:\n",
    "    settings = json.load(settings_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [puuid, match_id, indiv_pos, role, team_pos, lane, kills, assists, deaths, 2_kills, 3_kills, 4_kills, 5_kills, kill_spree, max_kill_spree, early_surr_try, early_surr, game_surr, neutral_kills, mini_kills, team_id, win, game_make, game_start, game_dur, game_end, prev_game_make, rest_time, streak_id]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 29 columns]\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the summoner info of X summoners\n",
    "# move start end time to settings\n",
    "summs_info = get_summoner_data(regs=settings[\"regions\"],\n",
    "                               tiers=settings[\"tiers\"],\n",
    "                               divs=settings['divisions'],\n",
    "                               sum_lim=settings['summoner_limit'],\n",
    "                               s_time=settings[\"start_time\"],\n",
    "                               e_time=settings[\"end_time\"],\n",
    "                               max_rest=settings[\"max_rest\"],\n",
    "                               min_streak=settings[\"min_streak\"])\n",
    "\n",
    "# # Store summoner data in a tsv file\n",
    "# summs_data_out = out_dir / \"summoner_data.tsv\"\n",
    "# with open(summs_data_out, \"w\") as out_file:    \n",
    "#     summs_info.to_csv(out_file, sep='\\t', index = False, line_terminator='\\n')\n",
    "\n",
    "\n",
    "# # Read in the summoner data\n",
    "# sumo_info = pd.read_csv(summs_data_out, sep = \"\\t\")\n",
    "\n",
    "\n",
    "print(summs_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base line\n",
    "# base line = all games of a player\n",
    "# tilt is calculated as win % er streak increase or decrease\n",
    "# % win on first game\n",
    "# % win on secoond game\n",
    "# % win on third game etc\n",
    "\n",
    "# make 2 datasets games long rest, games short rest \n",
    "# long rest >\n",
    "# short rest <=\n",
    "# \n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance of rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REst time vs win rate plot\n",
    "# \n",
    "# check if player has games with short rest take all games fitler is done later in data analysis\n",
    "# \n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHen to players play? \n",
    "# player to time point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tilt or in the zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winrate increase or decrease by factor of previous game\n",
    "# base winrate?\n",
    "# define good and bad stats using medians/average normal dist? \n",
    "# Win rate in next game after losing with bad stats\n",
    "# Win rate in next game after losing with good stats\n",
    "# Win rate in next game after winning with bad stats\n",
    "# Win rate in next game after winning with good stats\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
